# python -m streamlit run app.py


import streamlit as st
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use('default')
import os
import tensorflow as tf
import keras
import cv2
import spotipy
from spotipy.oauth2 import SpotifyOAuth
from spotipy.oauth2 import SpotifyClientCredentials
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity


# Load data
Music_data = pd.read_csv("music_with_mood.csv")
Music_data = Music_data[['name','artists', 'id','mood','popularity']]
faceCascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

#####################################################################################################
# Recommend Songs Based on Song
data_song_input = pd.read_csv("music_with_mood.csv")
data_song_input = data_song_input.sample(n=20000,random_state=42).reset_index(drop=True)


# Ch·ªçn c√°c ƒë·∫∑c tr∆∞ng s·ªë c·∫ßn thi·∫øt cho b√†i to√°n ph√¢n c·ª•m
# "valence" (ƒë·ªô s√°ng c·ªßa √¢m nh·∫°c), "danceability" (kh·∫£ nƒÉng nh·∫£y theo nh·∫°c),
# "energy" (m·ª©c nƒÉng l∆∞·ª£ng), "tempo" (nh·ªãp ƒëi·ªáu), 
# "acousticness" (ƒë·ªô m·ªôc), "liveness" (s·ª± s·ªëng ƒë·ªông),
# "speechiness" (ƒë·ªô n√≥i), "instrumentalness" (kh·∫£ nƒÉng kh√¥ng c√≥ l·ªùi b√†i h√°t).
numerical_features = [
    "valence", "danceability", "energy", "tempo", 
    "acousticness", "liveness", "speechiness", "instrumentalness"
]

# Chu·∫©n h√≥a c√°c ƒë·∫∑c tr∆∞ng s·ªë
# - Trung b√¨nh = 0
# - ƒê·ªô l·ªách chu·∫©n = 1
scaler = StandardScaler()
df_scaled = pd.DataFrame(
    scaler.fit_transform(data_song_input[numerical_features]), 
    columns=numerical_features                    
)

optimal_k = 5  # S·ªë c·ª•m t·ªëi ∆∞u
kmeans = KMeans(n_clusters=optimal_k, random_state=42)  # Kh·ªüi t·∫°o m√¥ h√¨nh K-Means
data_song_input["Cluster"] = kmeans.fit_predict(df_scaled)  # G√°n nh√£n c·ª•m cho t·ª´ng d√≤ng d·ªØ li·ªáu

# Tr·ª±c quan h√≥a c√°c c·ª•m b·∫±ng PCA (Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh)
from sklearn.decomposition import PCA

pca = PCA(n_components=2)  # Gi·∫£m d·ªØ li·ªáu xu·ªëng 2 chi·ªÅu ƒë·ªÉ tr·ª±c quan h√≥a
pca_result = pca.fit_transform(df_scaled)  # √Åp d·ª•ng PCA tr√™n d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a

# T·∫°o ma tr·∫≠n utility t·ª´ c√°c features
def create_utility_matrix(df):
    # Ch·ªçn c√°c features cho content-based filtering
    features = [
        "valence", "danceability", "energy", "tempo", 
        "acousticness", "liveness", "speechiness", "instrumentalness"
    ]
    
    # Chu·∫©n h√≥a features
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(df[features])
    
    # T·∫°o ma tr·∫≠n utility v·ªõi index l√† t√™n b√†i h√°t v√† columns l√† features
    utility_matrix = pd.DataFrame(
        features_scaled,
        index=df['name'],
        columns=features
    )
    
    return utility_matrix

# T·∫°o item profile
def create_item_profiles(df):
    # T·∫°o item profiles bao g·ªìm c·∫£ th√¥ng tin v·ªÅ cluster v√† c√°c ƒë·∫∑c tr∆∞ng kh√°c
    item_profiles = df[['name', 'artists', 'year', 'Cluster']].copy()
    
    # Th√™m c√°c features ƒë√£ chu·∫©n h√≥a t·ª´ utility matrix
    utility_matrix = create_utility_matrix(df)
    item_profiles = item_profiles.join(utility_matrix, on='name')
    
    return item_profiles

# T√≠nh to√°n ma tr·∫≠n similarity
def compute_similarity_matrix(utility_matrix):
    # T√≠nh ma tr·∫≠n similarity gi·ªØa c√°c b√†i h√°t
    similarity_matrix = cosine_similarity(utility_matrix)
    
    # Chuy·ªÉn v·ªÅ DataFrame ƒë·ªÉ d·ªÖ truy xu·∫•t
    similarity_df = pd.DataFrame(
        similarity_matrix,
        index=utility_matrix.index,
        columns=utility_matrix.index
    )
    
    return similarity_df

def recommend_songs(song_name, item_profiles, similarity_matrix, n_recommendations=5):
    """
    ƒê∆∞a ra g·ª£i √Ω d·ª±a tr√™n content-based filtering
    """
    # Ki·ªÉm tra xem b√†i h√°t c√≥ trong dataset kh√¥ng
    if song_name not in similarity_matrix.index:
        return "B√†i h√°t kh√¥ng c√≥ trong dataset"
    
    # L·∫•y cluster c·ªßa b√†i h√°t input
    song_cluster = item_profiles[item_profiles['name'] == song_name]['Cluster'].iloc[0]
    
    # L·∫•y danh s√°ch c√°c b√†i h√°t c√πng cluster
    same_cluster_songs = item_profiles[item_profiles['Cluster'] == song_cluster]
    
    # L·ªçc ma tr·∫≠n similarity cho c√°c b√†i h√°t c√πng cluster
    cluster_similarities = similarity_matrix.loc[song_name][same_cluster_songs['name']]
    
    # S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng ƒë·ªìng v√† l·∫•y n b√†i h√°t c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t
    most_similar = cluster_similarities.sort_values(ascending=False)[1:n_recommendations+1]
    
    # T·∫°o DataFrame k·∫øt qu·∫£ v·ªõi th√¥ng tin chi ti·∫øt
    recommendations = item_profiles[item_profiles['name'].isin(most_similar.index)].copy()
    recommendations['similarity_score'] = most_similar.values
    
    return recommendations[['name', 'artists', 'year', 'similarity_score']]

# T·∫°o c√°c ma tr·∫≠n v√† profiles
utility_matrix = create_utility_matrix(data_song_input)
item_profiles = create_item_profiles(data_song_input)
similarity_matrix = compute_similarity_matrix(utility_matrix)

# H√†m recommend_songs() s·∫Ω tr·∫£ v·ªÅ DataFrame ch·ª©a th√¥ng tin c√°c b√†i h√°t ƒë∆∞·ª£c g·ª£i √Ω
def get_recommendations(song_name, n_recommendations=5):
    recommendations = recommend_songs(
        song_name,
        item_profiles,
        similarity_matrix,
        n_recommendations
    )
    print(f"\nRecommendations for '{song_name}':")
    return recommendations

#####################################################################################################
# Load pre-trained model and class names
CNN_Model = load_model("CNN_model.h5")
Emotion_Classes = ['Happy', 'Disgust', 'Fear', 'Angry', 'Neutral', 'Sad', 'Surprise']

# Making Songs Recommendations Based on Predicted Class
def Recommend_Songs(pred_class, Num_song_rcm=5):
    
    if( pred_class=='Disgust' ):

        music = Music_data[Music_data['mood'] =='Sad' ]
        music = music.sort_values(by="popularity", ascending=False)
        music = music[:Num_song_rcm].reset_index(drop=True)
        return music

    if( pred_class=='Happy' or pred_class=='Sad' ):

        music = Music_data[Music_data['mood'] =='Happy' ]
        music = music.sort_values(by="popularity", ascending=False)
        music = music[:Num_song_rcm].reset_index(drop=True)
        return music

    if( pred_class=='Fear' or pred_class=='Angry' ):

        music = Music_data[Music_data['mood'] =='Calm' ]
        music = music.sort_values(by="popularity", ascending=False)
        music = music[:Num_song_rcm].reset_index(drop=True)
        return music

    if( pred_class=='Surprise' or pred_class=='Neutral' ):

        music = Music_data[Music_data['mood'] =='Energetic' ]
        music = music.sort_values(by="popularity", ascending=False)
        music = music[:Num_song_rcm].reset_index(drop=True)
        return music

def load_and_prep_image(image: np.ndarray):
    """
    Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o cho model CNN.
    """
    # Chuy·ªÉn sang ·∫£nh x√°m
    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Ph√°t hi·ªán khu√¥n m·∫∑t
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(gray_img, 1.1, 4)
    
    # N·∫øu t√¨m th·∫•y khu√¥n m·∫∑t, c·∫Øt v√† x·ª≠ l√Ω v√πng khu√¥n m·∫∑t
    if len(faces) > 0:
        x, y, w, h = faces[0]
        face_img = image[y:y + h, x:x + w]
    else:
        face_img = image  # N·∫øu kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t, s·ª≠ d·ª•ng ·∫£nh g·ªëc
    
    # Chuy·ªÉn sang RGB v√† resize v·ªÅ k√≠ch th∆∞·ªõc 48x48
    rgb_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
    rgb_img = cv2.resize(rgb_img, (48, 48))
    rgb_img = rgb_img / 255.0  # Chu·∫©n h√≥a
    return rgb_img

def predict_emotion(image: np.ndarray):
    """
    D·ª± ƒëo√°n c·∫£m x√∫c t·ª´ ·∫£nh ƒë·∫ßu v√†o.
    """
    processed_image = load_and_prep_image(image)
    img_batch = np.expand_dims(processed_image, axis=0)
    pred = CNN_Model.predict(img_batch)
    pred_class = Emotion_Classes[np.argmax(pred)]
    return pred_class, pred[0]

def display_recommendations(emotion, Num_song_rcm=5):
    # L·∫•y dataframe b√†i h√°t ƒë·ªÅ xu·∫•t
    recommended_songs_df = Recommend_Songs(emotion, Num_song_rcm)
    print(f"DataFrame returned: {recommended_songs_df}")  # In DataFrame ra ƒë·ªÉ ki·ªÉm tra

    if recommended_songs_df is not None:
        
        # Chuy·ªÉn t·∫•t c·∫£ d·ªØ li·ªáu th√†nh ki·ªÉu string n·∫øu c·∫ßn
        recommended_songs_df = recommended_songs_df.applymap(str)

        # ƒêi·ªÅu ch·ªânh ƒë·ªãnh d·∫°ng DataFrame (v√≠ d·ª•: ch·ªâ hi·ªÉn th·ªã c√°c c·ªôt quan tr·ªçng)
        displayed_df = recommended_songs_df[['name', 'artists', 'mood', 'popularity']]

        # Hi·ªÉn th·ªã DataFrame v·ªõi chi·ªÅu r·ªông c√°c c·ªôt t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh
        st.dataframe(displayed_df, width=1200)  # ƒêi·ªÅu ch·ªânh chi·ªÅu r·ªông c·ªßa DataFrame
        
        # T·∫°o c√°c button "Nghe" cho m·ªói b√†i h√°t
        for index, row in recommended_songs_df.iterrows():
            song_id = row['name']  # L·∫•y ID b√†i h√°t 
            if st.button(f"Nghe {row['name']}", key=f"play_button_{index}"):
                play_song_on_spotify(song_id)

    else:
        st.error("Kh√¥ng c√≥ b√†i h√°t ƒë·ªÅ xu·∫•t!")

###
# Spotify API
###
from spotipy.oauth2 import SpotifyClientCredentials
def play_song_on_spotify(song_name):
    """
    T√¨m ki·∫øm b√†i h√°t v√† t·∫°o link tr·ª±c ti·∫øp ƒë·∫øn Spotify.
    Ph√°t nh·∫°c tr·ª±c ti·∫øp tr√™n trang web (n·∫øu c√≥ ƒëi·ªÅu ki·ªán).

    """
    try:
        # Kh·ªüi t·∫°o Spotify client v·ªõi client credentials
        client_credentials_manager = SpotifyClientCredentials(
            client_id="6fe0ab17a16546c1a1f9032f1b154625",
            client_secret="bc68112c81324882bc092f8c42f8ca6d"
        )
        sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)

        # T√¨m ki·∫øm b√†i h√°t
        result = sp.search(q=song_name, type="track", limit=1)

        if result['tracks']['items']:
            track = result['tracks']['items'][0]
            track_id = track['id']
            track_name = track['name']
            artist_name = track['artists'][0]['name']

            embedded = f'<iframe src="https://open.spotify.com/embed/track/{track_id}" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>'
            # Hi·ªÉn th·ªã th√¥ng tin b√†i h√°t
            st.write(f"üéµ ƒêang ph√°t: **{track_name}** - {artist_name}")

            # Nh√∫ng Spotify player
            st.components.v1.html(
                embedded,
                height=400
            )

        else:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y b√†i h√°t tr√™n Spotify!")

    except Exception as e:
        st.error(f"‚ùå L·ªói khi t√¨m ki·∫øm: {str(e)}")    
    
        
def show_recommendations_tab():
    # Kh·ªüi t·∫°o session state n·∫øu ch∆∞a c√≥
    if 'recommended_songs_df' not in st.session_state:
        st.session_state.recommended_songs_df = None
    if 'search_performed' not in st.session_state:
        st.session_state.search_performed = False

    with st.container():
        col1, col2 = st.columns([3, 1])
        
        with col1:
            song_name = st.text_input("Nh·∫≠p t√™n b√†i h√°t:", key="song_input")
            if st.button("T√¨m ki·∫øm", key="search_button_2"):
                # L∆∞u k·∫øt qu·∫£ v√†o session state
                recommended_songs = get_recommendations(song_name, n_recommendations=Num_song_rcm)
                st.session_state.recommended_songs_df = recommended_songs.applymap(str)
                st.session_state.search_performed = True
           

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu ƒë√£ t√¨m ki·∫øm
    if st.session_state.search_performed and st.session_state.recommended_songs_df is not None:
        # Container cho DataFrame
        with st.container():
            displayed_df = st.session_state.recommended_songs_df[['name', 'artists', 'year', 'similarity_score']]
            st.dataframe(displayed_df, width=1200)
            
            # T·∫°o c√°c button "Nghe" cho m·ªói b√†i h√°t
            for index, row in displayed_df.iterrows():
                song_id = row['name']  # L·∫•y ID b√†i h√°t 
                if st.button(f"Nghe {row['name']}", key=f"play_button_{index}"):
                    play_song_on_spotify(song_id)
        

# Streamlit UI
# Slider ƒëi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng b√†i h√°t ƒë·ªÅ xu·∫•t
Num_song_rcm = st.sidebar.slider(
    "S·ªë l∆∞·ª£ng b√†i h√°t ƒë·ªÅ xu·∫•t:", 
    0, 30, 5, 1
    # Min, Max, Default, Step
)
st.title("MUSIC RECOMMENDATION SYSTEM")
tab1, tab2, tab3 = st.tabs(["Recommend based on emotion", "Recommend based on song", "Search for song"])
with tab1:
    st.write("Ch·ª•p ·∫£nh t·ª´ camera, t·∫£i l√™n ho·∫∑c n√≥i ra c·∫£m x√∫c c·ªßa b·∫°n h√¥m nay!")
    # Ch·ªçn ngu·ªìn ·∫£nh
    option = st.radio("Ch·ªçn ngu·ªìn:", ("Ch·ª•p t·ª´ camera", "T·∫£i ·∫£nh l√™n", "Nh·∫≠p c·∫£m x√∫c"))
    if option == "Ch·ª•p t·ª´ camera":
        # Ch·ª•p ·∫£nh t·ª´ camera
        if st.button("Ch·ª•p ·∫£nh"):
            cap = cv2.VideoCapture(0)
            ret, frame = cap.read()
            if ret:
                st.image(frame, channels="BGR", caption="·∫¢nh ch·ª•p t·ª´ camera")
                cap.release()
                
                # D·ª± ƒëo√°n c·∫£m x√∫c
                emotion, probabilities = predict_emotion(frame)
                st.subheader(f"C·∫£m x√∫c d·ª± ƒëo√°n: {emotion}")
                print(emotion)
                st.bar_chart(data=dict(zip(Emotion_Classes, probabilities)))
                st.write("ƒê·ªÅ xu·∫•t b√†i h√°t:")
                display_recommendations(emotion, Num_song_rcm)
            else:
                st.error("Kh√¥ng th·ªÉ truy c·∫≠p camera!")
                cap.release()

    elif option == "T·∫£i ·∫£nh l√™n":
        # T·∫£i ·∫£nh t·ª´ t·ªáp
        uploaded_file = st.file_uploader("T·∫£i ·∫£nh l√™n", type=["jpg", "jpeg", "png"])
        if uploaded_file:
            img = Image.open(uploaded_file)
            img_np = np.array(img)
            st.image(img, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)
            
            # D·ª± ƒëo√°n c·∫£m x√∫c
            emotion, probabilities = predict_emotion(img_np)
            st.subheader(f"C·∫£m x√∫c d·ª± ƒëo√°n: {emotion}")
            st.bar_chart(data=dict(zip(Emotion_Classes, probabilities)))
            st.write("ƒê·ªÅ xu·∫•t b√†i h√°t:")
            display_recommendations(emotion, Num_song_rcm)
    else:
        # Nh·∫≠p c·∫£m x√∫c
        emotion = st.selectbox("C·∫£m x√∫c c·ªßa b·∫°n h√¥m nay:", Emotion_Classes, index = 0, key="emotion_select")
        st.write("ƒê·ªÅ xu·∫•t b√†i h√°t:")
        display_recommendations(emotion, Num_song_rcm)
with tab2:
    show_recommendations_tab()
with tab3:
    st.write("T√¨m ki·∫øm b√†i h√°t v√† nghe tr·ª±c ti·∫øp tr√™n Spotify!")
    name = st.text_input("Nh·∫≠p t√™n b√†i h√°t:", key="song_search_input")
    if st.button("T√¨m ki·∫øm", key = "search_button_3"):
        play_song_on_spotify(name)
    
    

